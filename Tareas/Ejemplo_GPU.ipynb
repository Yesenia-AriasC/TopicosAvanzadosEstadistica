{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhlH5NlyOKeh"
   },
   "source": [
    "# Función para leer el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6RTc6um0N0iE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "def load_mnist(ruta, tipo='train'):\n",
    "\n",
    "\n",
    "    ruta_categorias = os.path.join(ruta, '%s-labels-idx1-ubyte.gz' % tipo)\n",
    "    ruta_imagenes = os.path.join(ruta, '%s-images-idx3-ubyte.gz' % tipo)\n",
    "    \n",
    "    with gzip.open(ruta_categorias, 'rb') as rut_cat:\n",
    "        etiquetas = np.frombuffer(rut_cat.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(ruta_imagenes, 'rb') as rut_imgs:\n",
    "        imagenes = np.frombuffer(rut_imgs.read(), dtype=np.uint8, offset=16).reshape(len(etiquetas), 784)\n",
    "\n",
    "    return imagenes, etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8CzPyppOlEm"
   },
   "source": [
    "# Acceso a Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtlvzO6VOrdT",
    "outputId": "3c39de5a-b88e-4a5c-949a-a608f9931488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "ruta = 'gdrive/My Drive/Colab Notebooks/fashion_mnist_data'\n",
    "\n",
    "X_train, Y_train = load_mnist(ruta, tipo='train')\n",
    "X_test, Y_test = load_mnist(ruta, tipo='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5bCuLxIQNdp"
   },
   "source": [
    "# Reajustar sets de datos\n",
    "\n",
    "Esto se hace para garantizar que el set de entrenamiento tenga un numero de datos que sea multiplo de 128 porque en el caso de la TPU se necesita esto (no se necesita en CPU ni GPU pero se hace para comparar de mejor manera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jVAvneTQQQ9a"
   },
   "outputs": [],
   "source": [
    "X_train = X_train[0:59904,:]\n",
    "X_test = X_test[0:9984,:]\n",
    "Y_train = Y_train[0:59904]\n",
    "Y_test = Y_test[0:9984]\n",
    "\n",
    "X_train = np.reshape(X_train,(59904,28,28,1))\n",
    "X_test = np.reshape(X_test,(9984,28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTcEIN9KS3Yw"
   },
   "source": [
    "# Implementar modelo\n",
    "## Importar Tensorflow 2 (ya incluye Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwBM2Tr2THAV",
    "outputId": "27f844c6-8878-4a9e-ec8a-7e717d0666d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
      "You set: `2.x   # Para garantizar que la versión 2.x sea importada`. This will be interpreted as: `2.x`.\n",
      "\n",
      "\n",
      "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
      "Versión de TensorFlow: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x   # Para garantizar que la versión 2.x sea importada\n",
    "import tensorflow as tf\n",
    "print('Versión de TensorFlow: ' + tf.__version__)\n",
    "\n",
    "tf.random.set_seed(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hPY6HHRTq-J"
   },
   "source": [
    "## Creación del modelo convolucional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TpAUwBvUKcg"
   },
   "source": [
    "Lo siguiente son 3 capas convolucionales que son prácticamente iguales:\n",
    "\n",
    "1. **Normalización:** Facilita convergencia del entrenamiento.\n",
    "2. **Filtros convolicionales.**\n",
    "3. **Capa MaxPooling.**\n",
    "4. **Capa Dropout:** Para reducir [overfitting](https://protecciondatos-lopd.com/empresas/overfitting/) del modelo.\n",
    "\n",
    "~~~\n",
    "Se dice que un modelo estadístico está sobreajustado cuando lo entrenamos con muchos datos. Cuando un modelo se entrena con tantos datos, comienza a aprender del ruido y las entradas de datos inexactas en nuestro conjunto de datos. Entonces, el modelo no categoriza los datos correctamente, debido a demasiados detalles y ruido.  \n",
    "~~~\n",
    "\n",
    "La única diferencia entre las 3 capas es el número de filtros convolucionales usados: 64, 128 y 256.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t3VuIss2Tu4P"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2I9aYqDXqjX"
   },
   "source": [
    "Después de la tercera capa convolucional aplanamos los datos (usando el módulo Flatten) y agregamos una Red Neuronal con 256 neuronas, que posteriormente conectaremos a la salida, la cual contendrá 10 neuronas y tendrá una función de activación softmax para clasificar cada una de las imágenes entrantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etJ8ThKJXq_6",
    "outputId": "5aac0104-61da-4103-da23-9ec1ed987a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,619,470\n",
      "Trainable params: 1,619,084\n",
      "Non-trainable params: 386\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.Activation('elu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAaDp9mGemUv"
   },
   "source": [
    "## Verificar disponibilidad de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0USt8s4AewJo",
    "outputId": "ef48b047-8446-4bd9-a6d8-898c0aae1699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU encontrada: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "nombre_gpu = tf.test.gpu_device_name()\n",
    "if nombre_gpu != '/device:GPU:0':\n",
    "  raise SystemError('GPU no encontrada')\n",
    "print('GPU encontrada: {}'.format(nombre_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpeYH96KYb-9"
   },
   "source": [
    "## Entrenamiento con GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf5b-VKwYu5w"
   },
   "source": [
    "Compilamos el modelo (elegimos optimizador a usar, función de error, entropía cruzada y la métrica de desempeño)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "90IceOGjYhwb"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHRhx1TUZQJN",
    "outputId": "a5158f39-922e-4575-ba4b-1a3f27246bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "468/468 [==============================] - 51s 40ms/step - loss: 0.6833 - accuracy: 0.7837 - val_loss: 0.3833 - val_accuracy: 0.8664\n",
      "Epoch 2/2\n",
      "468/468 [==============================] - 18s 39ms/step - loss: 0.3952 - accuracy: 0.8614 - val_loss: 0.3365 - val_accuracy: 0.8839\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def entrenamiento_gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1)\n",
    "  \n",
    "  return None\n",
    "\n",
    "gpu_time = timeit.timeit('entrenamiento_gpu()', number=1, setup='from __main__ import entrenamiento_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkzdjV7SgXtY",
    "outputId": "664fcece-3a20-4912-88c4-d2244ff7e2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo de entrenamiento: 82.98278205500003 segundos\n"
     ]
    }
   ],
   "source": [
    "print('tiempo de entrenamiento: '+str(gpu_time)+' segundos')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Ejemplo_GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
